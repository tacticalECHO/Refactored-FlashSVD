# FlashSVD Repository Structure After Refactoring

## ğŸ“ Complete Directory Tree

```
FlashSVD/
â”œâ”€â”€ ğŸ“¦ Core Package (Production Layer - M1-M5 Complete)
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ __init__.py                          # Mark src as package
â”‚       â”‚
â”‚       â”œâ”€â”€ flashsvd/                            # âœ¨ Main package (pip install flashsvd)
â”‚       â”‚   â”œâ”€â”€ __init__.py                      # Version: 0.1.0, module exports
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ cli.py                           # M4: Unified CLI entry (flashsvd)
â”‚       â”‚   â”œâ”€â”€ compress.py                      # M2: Compression pipeline main entry
â”‚       â”‚   â”œâ”€â”€ evaluate.py                      # M3: Evaluation pipeline main entry
â”‚       â”‚   â”œâ”€â”€ info.py                          # M4: Checkpoint info display
â”‚       â”‚   â”œâ”€â”€ io.py                            # M2: Model load/save + structure recovery
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ compression/                     # M2: Compression method implementations
â”‚       â”‚   â”‚   â”œâ”€â”€ __init__.py                  # compress_model() dispatcher
â”‚       â”‚   â”‚   â”œâ”€â”€ _metadata.py                 # compression_info.json generation
â”‚       â”‚   â”‚   â”œâ”€â”€ registry.py                  # Method registry
â”‚       â”‚   â”‚   â”œâ”€â”€ method_args.py               # Method argument validation
â”‚       â”‚   â”‚   â”œâ”€â”€ standard_svd.py              # Standard SVD (BERT)
â”‚       â”‚   â”‚   â”œâ”€â”€ roberta_svd.py               # RoBERTa-specific SVD
â”‚       â”‚   â”‚   â”œâ”€â”€ fwsvd.py                     # Fisher-Weighted SVD
â”‚       â”‚   â”‚   â”œâ”€â”€ adasvd.py                    # Adaptive Rank Selection
â”‚       â”‚   â”‚   â””â”€â”€ whiten.py                    # DRONE (Data-Aware Whitening)
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ finetune/                        # âœ¨ M6: Fine-tuning module (new)
â”‚       â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”‚   â”œâ”€â”€ config.py                    # FinetuneConfig dataclass
â”‚       â”‚   â”‚   â””â”€â”€ trainer.py                   # Fine-tuning trainer
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ kernels/                         # M1: Kernel wrapper layer (thin)
â”‚       â”‚   â”‚   â””â”€â”€ __init__.py                  # Re-export src.kernels.*
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ utils/                           # M1: Utils wrapper layer (thin)
â”‚       â”‚   â”‚   â””â”€â”€ __init__.py                  # Re-export src.utils.*
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ ui/                              # M5: Gradio Web UI
â”‚       â”‚       â”œâ”€â”€ __init__.py
â”‚       â”‚       â””â”€â”€ app.py                       # Gradio interface (3 tabs: compress/eval/info)
â”‚       â”‚
â”‚       â”œâ”€â”€ kernels/                             # Original Triton kernels (research impl, keep unchanged)
â”‚       â”‚   â”œâ”€â”€ flash_attn_triton.py             # FlashAttention baseline
â”‚       â”‚   â”œâ”€â”€ flashsvdattn.py                  # Rank-aware Fused Attention
â”‚       â”‚   â”œâ”€â”€ flashsvdffnv1.py                 # FFN v1 (two-stage fusion)
â”‚       â”‚   â””â”€â”€ flashsvdffnv2.py                 # FFN v2 (full fusion, theoretically optimal)
â”‚       â”‚
â”‚       â””â”€â”€ utils/                               # Original SVD utilities (research impl, keep unchanged)
â”‚           â”œâ”€â”€ SVDBlocks.py                     # Non-rank-aware blocks (baseline)
â”‚           â”œâ”€â”€ FlashSVDBlocks.py                # Rank-aware blocks (core)
â”‚           â”œâ”€â”€ fwsvd.py                         # FWSVD math implementation
â”‚           â”œâ”€â”€ svd_helpers.py                   # SVD decomposition helpers
â”‚           â”œâ”€â”€ metrics.py                       # Evaluation metrics (acc_peak_time)
â”‚           â””â”€â”€ kernel_api.py                    # Kernel API interface
â”‚
â”œâ”€â”€ ğŸ§ª Experiment Directories (Research Code Archive)
â”‚   â”œâ”€â”€ experiments/                             # âœ¨ Reorganized encoder experiments
â”‚   â”‚   â”œâ”€â”€ BERT/                                # Standard BERT + SVD
â”‚   â”‚   â”‚   â”œâ”€â”€ profile_dense.py                 # Dense baseline performance
â”‚   â”‚   â”‚   â”œâ”€â”€ profile_svd.py                   # SVD + dense kernels
â”‚   â”‚   â”‚   â””â”€â”€ profile_flashsvd.py              # SVD + FlashSVD kernels
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ BERTFW/                              # BERT + Fisher-Weighted SVD
â”‚   â”‚   â”‚   â”œâ”€â”€ profile_dense.py
â”‚   â”‚   â”‚   â”œâ”€â”€ profile_fwsvd.py                 # FWSVD + dense kernels
â”‚   â”‚   â”‚   â”œâ”€â”€ profile_flashfwsvd.py            # FWSVD + FlashSVD kernels
â”‚   â”‚   â”‚   â””â”€â”€ profile_flashfwsvd_offload.py    # With CPU offloading
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ BERTAda/                             # BERT + Adaptive Rank Selection
â”‚   â”‚   â”‚   â”œâ”€â”€ adaptive_rank_selection.py       # Rank selection training
â”‚   â”‚   â”‚   â”œâ”€â”€ ars_out/ranks.json               # Output rank configuration
â”‚   â”‚   â”‚   â””â”€â”€ profile_flashsvd.py              # Using adaptive ranks
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ BERTWhiten/                          # BERT + DRONE (Whitening)
â”‚   â”‚   â”‚   â”œâ”€â”€ profile_dense.py
â”‚   â”‚   â”‚   â”œâ”€â”€ profile_svd.py
â”‚   â”‚   â”‚   â””â”€â”€ profile_flashsvd.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ RoBERTa/                             # RoBERTa variants
â”‚   â”‚   â”‚   â”œâ”€â”€ profile_dense_roberta.py
â”‚   â”‚   â”‚   â”œâ”€â”€ profile_svd_roberta.py
â”‚   â”‚   â”‚   â””â”€â”€ profile_flashsvd_roberta.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ RoBERTaFW/                           # RoBERTa + FWSVD
â”‚   â”‚   â”‚   â”œâ”€â”€ profile_dense_roberta.py
â”‚   â”‚   â”‚   â”œâ”€â”€ profile_fwsvd_roberta.py
â”‚   â”‚   â”‚   â””â”€â”€ profile_flashfwsvd_roberta.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ModernBERT/                          # ModernBERT architecture
â”‚   â”‚       â”œâ”€â”€ BERT_MASK/                       # Standard masked attention
â”‚   â”‚       â”‚   â”œâ”€â”€ run_modernbert.py
â”‚   â”‚       â”‚   â”œâ”€â”€ run_modernbert_flashsvd.py
â”‚   â”‚       â”‚   â””â”€â”€ run_modernbert_svd.py
â”‚   â”‚       â”œâ”€â”€ BERT_FWMASK/                     # Forward-masked variant
â”‚   â”‚       â”‚   â”œâ”€â”€ run_modernbert_flashfwsvd.py
â”‚   â”‚       â”‚   â””â”€â”€ run_modernbert_fwsvd.py
â”‚   â”‚       â”œâ”€â”€ BERT_LONG/                       # Long-context variant
â”‚   â”‚       â”‚   â””â”€â”€ profile_imdb.py
â”‚   â”‚       â”œâ”€â”€ eval_modernbert.py
â”‚   â”‚       â”œâ”€â”€ train_modernbert.py
â”‚   â”‚       â””â”€â”€ train_modernbert_long.py
â”‚   â”‚
â”‚   â””â”€â”€ legacy/                                  # âœ¨ Old file archive (M0 cleanup)
â”‚       â”œâ”€â”€ BERT/                                # Original BERT experiments before move
â”‚       â”œâ”€â”€ BERTAda/
â”‚       â”œâ”€â”€ BERTFW/
â”‚       â”œâ”€â”€ BERTWhiten/
â”‚       â”œâ”€â”€ RoBERTa/
â”‚       â”œâ”€â”€ RoBERTaFW/
â”‚       â”œâ”€â”€ ModernBERT/
â”‚       â”œâ”€â”€ app.py                               # Old Gradio training UI
â”‚       â”œâ”€â”€ train_bert_unified_min.py            # Old unified training script
â”‚       â””â”€â”€ utils_nlp.py                         # Old NLP utilities
â”‚
â”œâ”€â”€ ğŸ”¬ Decoder Experiments (Keep in root, independently maintained)
â”‚   â”œâ”€â”€ decoders/
â”‚   â”‚   â”œâ”€â”€ gpt2/                                # GPT-2 + SVD/ASVD
â”‚   â”‚   â”‚   â”œâ”€â”€ kernels/                         # Causal attention kernels
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ flash_attn_causal.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ flashsvdattn.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ flashsvdffn.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ utils_mask.py
â”‚   â”‚   â”‚   â”œâ”€â”€ with_finetune/                   # Fine-tuning examples
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ finetune_lowrank.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ infer_lowrank.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ lowrank_gpt2.py
â”‚   â”‚   â”‚   â”œâ”€â”€ profile_dense.py
â”‚   â”‚   â”‚   â”œâ”€â”€ profile_asvd.py                  # Activation-aware SVD
â”‚   â”‚   â”‚   â”œâ”€â”€ profile_asvd_accum_flash.py
â”‚   â”‚   â”‚   â”œâ”€â”€ profile_asvd_accum_flashsvd.py
â”‚   â”‚   â”‚   â””â”€â”€ profile_svd_kv.py                # KV-cache compression
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ llama/                               # LLaMA-2-7B + SVD/ASVD
â”‚   â”‚       â”œâ”€â”€ asvd_rep/                        # ASVD method reproduction
â”‚   â”‚       â”‚   â”œâ”€â”€ huggingface_repos/           # HF model integration
â”‚   â”‚       â”‚   â”œâ”€â”€ modules/svd_linear.py
â”‚   â”‚       â”‚   â”œâ”€â”€ utils/                       # ASVD utilities
â”‚   â”‚       â”‚   â””â”€â”€ profile_*.py
â”‚   â”‚       â”œâ”€â”€ kernels/                         # RoPE + causal kernels
â”‚   â”‚       â”‚   â”œâ”€â”€ flash_attn_causal.py
â”‚   â”‚       â”‚   â”œâ”€â”€ flashsvdropeattn.py          # RoPE + FlashSVD
â”‚   â”‚       â”‚   â””â”€â”€ flashsvdswiglu.py            # SwiGLU fusion
â”‚   â”‚       â”œâ”€â”€ eval/
â”‚   â”‚       â”‚   â”œâ”€â”€ profile_asvd_flashsvd_llama.py
â”‚   â”‚       â”‚   â””â”€â”€ profile_asvd_llama.py
â”‚   â”‚       â””â”€â”€ profile_*.py
â”‚   â”‚
â”‚   â”œâ”€â”€ benchmark/                               # Kernel performance micro-benchmarks
â”‚   â”‚   â”œâ”€â”€ encoder_kernel/                      # Encoder kernel benchmarks
â”‚   â”‚   â”‚   â”œâ”€â”€ flash_attn_triton.py
â”‚   â”‚   â”‚   â”œâ”€â”€ flashsvdattn.py
â”‚   â”‚   â”‚   â”œâ”€â”€ flashsvdffn.py
â”‚   â”‚   â”‚   â”œâ”€â”€ flashsvdffnv1.py
â”‚   â”‚   â”‚   â””â”€â”€ utils_mask.py
â”‚   â”‚   â”œâ”€â”€ decoder_kernel/                      # Decoder kernel benchmarks
â”‚   â”‚   â”‚   â”œâ”€â”€ flash_attn_causal.py
â”‚   â”‚   â”‚   â”œâ”€â”€ flashsvdropeattn.py
â”‚   â”‚   â”‚   â””â”€â”€ flashsvdswiglu.py
â”‚   â”‚   â”œâ”€â”€ benchmark/                           # CSV result outputs
â”‚   â”‚   â”‚   â”œâ”€â”€ decoder_attn_decode.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ decoder_attn_prefill.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ decoder_ffn_long_context.csv
â”‚   â”‚   â”‚   â””â”€â”€ long_context_ffn.csv
â”‚   â”‚   â”œâ”€â”€ benchmark_flashsvdattn_ranks.py      # Attention rank sweep
â”‚   â”‚   â”œâ”€â”€ benchmark_flashsvdffn.py             # FFN benchmarks
â”‚   â”‚   â”œâ”€â”€ benchmark_long_context_attn.py       # Long-context attention
â”‚   â”‚   â”œâ”€â”€ benchmark_long_context_decoder_attn.py
â”‚   â”‚   â”œâ”€â”€ benchmark_long_context_decoder_ffn.py
â”‚   â”‚   â””â”€â”€ benchmark_long_context_ffn.py
â”‚   â”‚
â”‚   â”œâ”€â”€ train/                                   # Training utilities (old, reference only)
â”‚   â”‚   â”œâ”€â”€ train_bert.py
â”‚   â”‚   â”œâ”€â”€ train_bert_mlm.py
â”‚   â”‚   â”œâ”€â”€ train_roberta.py
â”‚   â”‚   â”œâ”€â”€ train_roberta_large.py
â”‚   â”‚   â””â”€â”€ train_roberta_mlm.py
â”‚   â”‚
â”‚   â””â”€â”€ why_finetuning/                          # Fine-tuning ablation studies
â”‚       â”œâ”€â”€ kernel/                              # Fine-tuning-specific kernels
â”‚       â”‚   â”œâ”€â”€ flash_attn_triton.py
â”‚       â”‚   â”œâ”€â”€ flashsvdattn.py
â”‚       â”‚   â””â”€â”€ flashsvdffn*.py
â”‚       â”œâ”€â”€ finetune_svd.py                      # Fine-tuning experiment scripts
â”‚       â”œâ”€â”€ finetune_svd_saveable.py
â”‚       â”œâ”€â”€ inference_svd_model.py
â”‚       â””â”€â”€ profile_*.py
â”‚
â”œâ”€â”€ ğŸ§° Test Suite (M4-M6 New)
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ scripts/                             # Test scripts
â”‚       â”‚   â”œâ”€â”€ test_all_methods.py              # Python test suite
â”‚       â”‚   â”œâ”€â”€ test_all_methods.sh              # Full test workflow
â”‚       â”‚   â”œâ”€â”€ test_compression_only.sh         # Compression-only tests
â”‚       â”‚   â”œâ”€â”€ test_compression_r64_flat.sh     # Rank=64 flat tests
â”‚       â”‚   â”œâ”€â”€ test_finetuned_models.py         # Fine-tuned model tests
â”‚       â”‚   â”œâ”€â”€ test_finetuned_organization.py   # Directory structure tests
â”‚       â”‚   â””â”€â”€ test_svd_reconstruction.py       # SVD reconstruction tests
â”‚       â”‚
â”‚       â”œâ”€â”€ logs/                                # Test log outputs
â”‚       â”‚   â”œâ”€â”€ test_YYYYMMDD_HHMMSS.log
â”‚       â”‚   â””â”€â”€ ...
â”‚       â”‚
â”‚       â”œâ”€â”€ results/                             # Test results
â”‚       â”‚   â”œâ”€â”€ test_report_YYYYMMDD.json
â”‚       â”‚   â”œâ”€â”€ benchmark_summary.csv
â”‚       â”‚   â””â”€â”€ ...
â”‚       â”‚
â”‚       â””â”€â”€ docs/                                # Test documentation
â”‚           â”œâ”€â”€ TEST_PLAN.md
â”‚           â””â”€â”€ IMPLEMENTATION_NOTES.md
â”‚
â”œâ”€â”€ ğŸ“ Models and Outputs
â”‚   â”œâ”€â”€ models/                                  # Fine-tuned model storage
â”‚   â”‚   â”œâ”€â”€ README.md                            # Directory structure explanation
â”‚   â”‚   â””â”€â”€ bert-sst2-finetuned/                 # Example: fine-tuned BERT
â”‚   â”‚       â”œâ”€â”€ config.json
â”‚   â”‚       â”œâ”€â”€ pytorch_model.bin
â”‚   â”‚       â”œâ”€â”€ tokenizer_config.json
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ compressed_models/                       # âœ¨ Compressed model outputs (auto-created)
â”‚   â”‚   â””â”€â”€ bert-base-uncased_fwsvd_r64/         # Example: compressed checkpoint
â”‚   â”‚       â”œâ”€â”€ config.json                      # HF model config
â”‚   â”‚       â”œâ”€â”€ model.safetensors                # HF weights
â”‚   â”‚       â”œâ”€â”€ flashsvd_state_dict.pt           # FlashSVD state (structure recovery)
â”‚   â”‚       â””â”€â”€ compression_info.json            # Compression metadata
â”‚   â”‚
â”‚   â”œâ”€â”€ compression_test/                        # Compression test outputs
â”‚   â”‚   â”œâ”€â”€ standard/
â”‚   â”‚   â”œâ”€â”€ fw/
â”‚   â”‚   â”œâ”€â”€ ada/
â”‚   â”‚   â””â”€â”€ whiten/
â”‚   â”‚
â”‚   â”œâ”€â”€ compression_test_r64_flat/               # Rank=64 flat tests
â”‚   â”‚   â”œâ”€â”€ standard/
â”‚   â”‚   â”œâ”€â”€ fw/
â”‚   â”‚   â”œâ”€â”€ whiten/
â”‚   â”‚   â””â”€â”€ results/
â”‚   â”‚
â”‚   â”œâ”€â”€ test_output/                             # Test temporary outputs
â”‚   â”‚   â”œâ”€â”€ bert/
â”‚   â”‚   â””â”€â”€ cli_test/
â”‚   â”‚
â”‚   â””â”€â”€ figs/                                    # Figure resources
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ ğŸ“ Configuration Files
â”‚   â”œâ”€â”€ pyproject.toml                           # âœ¨ M1: Modern packaging config (PEP 621)
â”‚   â”‚   # [project]
â”‚   â”‚   #   name = "flashsvd"
â”‚   â”‚   #   version = "0.1.0"
â”‚   â”‚   #   dependencies = [torch, transformers, ...]
â”‚   â”‚   # [project.scripts]
â”‚   â”‚   #   flashsvd = "flashsvd.cli:main"
â”‚   â”‚   #   flashsvd-compress = "flashsvd.compress:main"
â”‚   â”‚   #   flashsvd-eval = "flashsvd.evaluate:main"
â”‚   â”‚   #   flashsvd-info = "flashsvd.info:main"
â”‚   â”‚   #   flashsvd-finetune = "flashsvd.finetune:main"
â”‚   â”‚   #   flashsvd-ui = "flashsvd.ui.app:main"
â”‚   â”‚
â”‚   â”œâ”€â”€ requirements.txt                         # Dependency list
â”‚   â”œâ”€â”€ environment.yml                          # Conda environment config
â”‚   â”œâ”€â”€ .gitignore                               # Git ignore rules
â”‚   â””â”€â”€ install_local.sh                         # Local installation script
â”‚
â”œâ”€â”€ ğŸ“š Documentation (M4-M6 Enhanced)
â”‚   â”œâ”€â”€ README.md                                # âœ¨ Main README (updated: CLI+UI+benchmarks)
â”‚   â”œâ”€â”€ CLAUDE.md                                # âœ¨ Project guidance doc (must read for dev!)
â”‚   â”œâ”€â”€ CHANGELOG.md                             # âœ¨ Version changelog
â”‚   â”œâ”€â”€ CONTRIBUTING.md                          # âœ¨ Contribution guide
â”‚   â”œâ”€â”€ LICENSE                                  # MIT License
â”‚   â”‚
â”‚   â”œâ”€â”€ REPO_STRUCTURE.md                        # âœ¨ This document (directory structure)
â”‚   â”œâ”€â”€ README_OLD_BACKUP.md                     # Old README backup
â”‚   â”‚
â”‚   â”œâ”€â”€ QUICK_START_UI.md                        # âœ¨ UI quick start guide
â”‚   â”œâ”€â”€ M5_UI_GUIDE.md                           # âœ¨ M5 UI detailed usage guide
â”‚   â”œâ”€â”€ FINETUNED_MODEL_ORGANIZATION.md          # âœ¨ Fine-tuned model organization
â”‚   â”œâ”€â”€ DATASET_GUIDE.md                         # âœ¨ Dataset usage guide
â”‚   â””â”€â”€ DATASET_QUICK_REFERENCE.md               # âœ¨ Dataset quick reference
â”‚
â””â”€â”€ ğŸ“„ Other Files
    â”œâ”€â”€ 2508.01506v1.pdf                         # FlashSVD paper PDF
    â””â”€â”€ ...

```

---

## ğŸ“Š Directory Responsibilities

### ğŸ¯ Product Layer (User Interaction)

| Directory/File | Responsibility | User-Visible | Status |
|----------------|----------------|--------------|--------|
| `src/flashsvd/cli.py` | Unified CLI entry | âœ… `flashsvd` | âœ… M4 Complete |
| `src/flashsvd/compress.py` | Compression API | âœ… `flashsvd compress` | âœ… M2 Complete |
| `src/flashsvd/evaluate.py` | Evaluation API | âœ… `flashsvd eval` | âœ… M3 Complete |
| `src/flashsvd/info.py` | Info display | âœ… `flashsvd info` | âœ… M4 Complete |
| `src/flashsvd/finetune/` | Fine-tuning API | âœ… `flashsvd finetune` | âœ… M6 Complete |
| `src/flashsvd/ui/app.py` | Web interface | âœ… `flashsvd-ui` | âœ… M5 Complete |

**Backward Compatibility**: Standalone commands `flashsvd-compress`, `flashsvd-eval`, `flashsvd-info`, `flashsvd-finetune` still available.

### ğŸ§© Business Logic Layer (Method Implementation)

| Directory/File | Responsibility | Called By | Status |
|----------------|----------------|-----------|--------|
| `src/flashsvd/compression/*.py` | Compression method implementations | compress.py | âœ… M2 Complete |
| `src/flashsvd/compression/registry.py` | Method registration & dispatch | compress.py | âœ… M2 Complete |
| `src/flashsvd/io.py` | Model load/save | compress.py, evaluate.py | âœ… M2 Complete |
| `src/flashsvd/finetune/trainer.py` | Fine-tuning trainer | finetune module | âœ… M6 Complete |

**Supported Compression Methods** (M2.0 Scope):
- âœ… `standard`: Standard SVD (BERT/RoBERTa)
- âœ… `fwsvd` / `fw`: Fisher-Weighted SVD
- âœ… `whiten` / `drone`: Data-aware Whitening (DRONE)
- âœ… `adasvd` / `ada`: Adaptive Rank Selection
- ğŸ”œ `asvd`: Activation-aware SVD (decoders, future)

### ğŸ”§ Low-Level Implementation (Original Research Code)

| Directory | Responsibility | Type | Modification Constraints |
|-----------|----------------|------|-------------------------|
| `src/kernels/` | Triton GPU kernels | Research impl | âŒ Do NOT modify (unless bugfix) |
| `src/utils/` | SVD math/blocks | Research impl | âŒ Do NOT modify (unless bugfix) |

### ğŸ§ª Experiment Code (Reference and Archive)

| Directory | Responsibility | Status | Purpose |
|-----------|----------------|--------|---------|
| `experiments/BERT*/` | Encoder experiments | âœ… Moved & preserved | Reference & logic extraction |
| `experiments/ModernBERT/` | ModernBERT experiments | âœ… Moved & preserved | Reference implementation |
| `legacy/` | Old file archive | âœ… Archived | Historical reference |
| `decoders/` | Decoder experiments | âœ… Keep in root | Independent maintenance |
| `benchmark/` | Performance benchmarks | âœ… Keep in root | Continuous benchmarking |

### ğŸ§° Testing and Validation

| Directory | Responsibility | Status |
|-----------|----------------|--------|
| `test/scripts/` | Test scripts | âœ… M4-M6 Complete |
| `test/logs/` | Test logs | âœ… Auto-generated |
| `test/results/` | Test results | âœ… Auto-generated |
| `compression_test/` | Compression test outputs | âœ… Auto-created |

---

## ğŸ”„ Code Flow Relationships

### Compression Flow

```
User
  â†“
flashsvd compress --model bert-base-uncased --task sst2 --method fwsvd --rank 64
  â†“
src/flashsvd/cli.py (parse command)
  â†“
src/flashsvd/compress.py::run_compress(CompressConfig)
  â†“
src/flashsvd/compression/__init__.py::compress_model() (dispatcher)
  â†“
src/flashsvd/compression/fwsvd.py::compress_bert_fwsvd() (method implementation)
  â†“
src/flashsvd/utils (wrapper layer) â†’ src/utils/fwsvd.py (FWSVD math)
  â†“
src/flashsvd/utils (wrapper layer) â†’ src/utils/FlashSVDBlocks.py (block construction)
  â†“
src/flashsvd/kernels (wrapper layer) â†’ src/kernels/flashsvdattn.py (Triton kernel)
  â†“
GPU execution
  â†“
src/flashsvd/io.py::save_compressed() (save checkpoint)
  â†“
compressed_models/bert-base-uncased_fwsvd_r64/
  â”œâ”€â”€ config.json (HF config + compression metadata)
  â”œâ”€â”€ model.safetensors (HF weights)
  â”œâ”€â”€ flashsvd_state_dict.pt (FlashSVD state)
  â””â”€â”€ compression_info.json (compression metadata)
```

### Evaluation Flow

```
User
  â†“
flashsvd eval --checkpoint ./compressed_models/bert-base-uncased_fwsvd_r64 --task sst2
  â†“
src/flashsvd/cli.py
  â†“
src/flashsvd/evaluate.py::run_eval(EvalConfig)
  â†“
src/flashsvd/io.py::load_compressed() (load model + structure recovery)
  â†“
src/utils/metrics.py::acc_peak_time() (evaluation metrics)
  â†“
Output JSON:
{
  "task": "sst2",
  "metric_name": "accuracy",
  "metric_value": 0.8991,
  "peak_memory_mib": 542,
  "latency_ms": 139.6,
  ...
}
```

### Fine-tuning Flow

```
User
  â†“
flashsvd finetune --checkpoint <compressed_model> --task sst2 --epochs 3
  â†“
src/flashsvd/cli.py
  â†“
src/flashsvd/finetune/__init__.py::main()
  â†“
src/flashsvd/finetune/trainer.py::train()
  â†“
models/finetuned/bert/fwsvd/<model_name>/
  â”œâ”€â”€ best/ (best checkpoint - use this!)
  â”œâ”€â”€ checkpoint-<epoch>-<step>/
  â””â”€â”€ tensorboard/
```

---

## ğŸ“¦ Package Structure After Installation

### Installation Commands

```bash
# Install PyTorch (must install first)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Install FlashSVD
cd FlashSVD
pip install -e .
```

### Python Import Paths

```python
# Version info
from flashsvd import __version__
print(__version__)  # "0.1.0"

# Compression API
from flashsvd.compress import CompressConfig, run_compress
config = CompressConfig(model="bert-base-uncased", task="sst2", method="fwsvd", rank=64)
run_compress(config)

# Evaluation API
from flashsvd.evaluate import EvalConfig, run_eval
eval_config = EvalConfig(checkpoint="./compressed_models/...", task="sst2")
results = run_eval(eval_config)

# Fine-tuning API
from flashsvd.finetune import FinetuneConfig
from flashsvd.finetune.trainer import train
ft_config = FinetuneConfig(checkpoint="./compressed_models/...", task="sst2")
train(ft_config)

# Compression method dispatcher
from flashsvd.compression import compress_model
compressed_model = compress_model(model, method="fwsvd", ranks={"attn": 64, "ffn": 384, "wo": 384})

# Low-level utilities (advanced users)
from flashsvd.utils import SVDBlocks, FlashSVDBlocks
from flashsvd.kernels import flashsvdattn
```

### Command-Line Tools

```bash
# Unified CLI (recommended)
flashsvd --help
flashsvd compress --help
flashsvd eval --help
flashsvd info --help
flashsvd finetune --help

# Standalone commands (backward compatible)
flashsvd-compress --help
flashsvd-eval --help
flashsvd-info --help
flashsvd-finetune --help
flashsvd-ui  # Launch web interface

# Example: Complete workflow
flashsvd compress --model textattack/bert-base-uncased-SST-2 --task sst2 --method fwsvd --rank 64
flashsvd eval --checkpoint ./compressed_models/bert-base-uncased-SST-2_fwsvd_r64 --task sst2
flashsvd finetune --checkpoint ./compressed_models/bert-base-uncased-SST-2_fwsvd_r64 --task sst2 --epochs 3
flashsvd info ./compressed_models/bert-base-uncased-SST-2_fwsvd_r64
```

---

## ğŸ¯ Design Principles

### âœ… Principles Followed

1. **Clear Layering** (Product â†’ Business â†’ Implementation)
   - **Product Layer**: `flashsvd/` (user interaction: CLI, UI, API)
   - **Business Layer**: `compression/`, `finetune/` (method implementations)
   - **Implementation Layer**: `utils/`, `kernels/` (research code)

2. **Backward Compatibility** (don't break old code)
   - Original experiment code preserved in `experiments/` and `decoders/`
   - Standalone commands (`flashsvd-compress` etc.) still available
   - New code calls old code via wrapper layers, doesn't modify old implementations

3. **Thin Wrapper Principle** (avoid duplicate implementation)
   - `flashsvd.utils` â†’ `src.utils` (re-export)
   - `flashsvd.kernels` â†’ `src.kernels` (re-export)
   - Compression methods extracted from experiment scripts, not rewritten

4. **DRY Principle** (Don't Repeat Yourself)
   - Compression logic implemented once in `compression/`
   - CLI/UI call same core functions (`run_compress`, `run_eval`)
   - Evaluation metrics reuse `src/utils/metrics.py`

5. **Extensibility**
   - New methods: add to `compression/`, register in `registry.py`
   - New architectures: inherit from `SVDBlock` base class
   - New tasks: extend `GLUE_TASKS` list

6. **Documentation-Driven**
   - `CLAUDE.md`: Development must-read (execution contract, milestones, prohibitions)
   - `REPO_STRUCTURE.md`: Directory structure (this document)
   - `CONTRIBUTING.md`: Contribution guide
   - `DATASET_GUIDE.md`: Dataset usage
   - `M5_UI_GUIDE.md`: UI usage guide

---

## ğŸš€ Key Improvements (M0 â†’ M6)

| Improvement | Before (Pre-M0) | After (M1-M6 Complete) | Milestone |
|-------------|-----------------|------------------------|-----------|
| **Package Structure** | None, scripts only | âœ… `pip install flashsvd` | M1 |
| **Command Line** | None | âœ… `flashsvd compress/eval/info/finetune` | M2-M4, M6 |
| **Web UI** | Old Gradio training UI | âœ… `flashsvd-ui` (compress/eval/info) | M5 |
| **Compression Methods** | Scattered in experiment dirs | âœ… Unified in `compression/` + registry | M2 |
| **Evaluation Pipeline** | Each script independently implemented | âœ… Unified `run_eval()` + JSON output | M3 |
| **Fine-tuning Pipeline** | Scattered implementations | âœ… Unified `finetune/` module + auto-organization | M6 |
| **Experiment Code** | Root directory chaos | âœ… `experiments/` organized, `legacy/` archived | M0 |
| **Import Paths** | Inconsistent (`from src.*`) | âœ… Unified `from flashsvd.*` | M1 |
| **Documentation** | README only | âœ… 8 documentation files (CLAUDE, CONTRIBUTING, etc.) | M4-M6 |
| **Testing** | None | âœ… Complete test suite (`test/scripts/`) | M4-M6 |
| **Checkpoint Format** | Inconsistent | âœ… HF `save_pretrained()` + metadata | M2 |

---

## ğŸ“ Important Documentation Index

### Must-Read Documents (Before Development)

1. **CLAUDE.md**: Project execution contract, milestone definitions, prohibitions âš ï¸
2. **REPO_STRUCTURE.md**: This document, directory structure and design principles
3. **README.md**: User documentation, installation and usage

### Quick Start (Users)

1. **README.md**: Installation and basic usage
2. **QUICK_START_UI.md**: Web UI quick start
3. **M5_UI_GUIDE.md**: Detailed UI usage guide

### Development Guide (Contributors)

1. **CONTRIBUTING.md**: Contribution guide and code standards
2. **CLAUDE.md**: Development constraints and milestones
3. **DATASET_GUIDE.md**: Dataset usage and extension

### Reference Documentation

1. **FINETUNED_MODEL_ORGANIZATION.md**: Fine-tuned model directory organization
2. **DATASET_QUICK_REFERENCE.md**: Dataset quick reference
3. **CHANGELOG.md**: Version changelog

---

## âœ… Current Status (2026-01-30)

### Completed (M1-M6)

- âœ… **M1**: Package structure (`pip install -e .` available)
- âœ… **M2**: Compression pipeline (standard SVD, FWSVD, Whiten, AdaSVD for encoders)
- âœ… **M3**: Evaluation pipeline (unified JSON output)
- âœ… **M4**: CLI interface (validation, progress bars, error handling)
- âœ… **M5**: Gradio UI (3 tabs: compress/eval/info)
- âœ… **M6**: Fine-tuning pipeline (auto-organization, best checkpoint saving)

### Future Extensions

- ğŸ”œ **M2.1**: Decoder compression (ASVD for GPT/LLaMA)
- ğŸ”œ **M2.2**: ModernBERT support
- ğŸ”œ **M7**: PyPI release (`pip install flashsvd`)
- ğŸ”œ **M8**: Docker image
- ğŸ”œ **M9**: Multi-GPU training support

---

## ğŸ” Quick File Reference

```bash
# Core product code
ls src/flashsvd/*.py                    # CLI, compress, eval, info
ls src/flashsvd/compression/*.py        # Compression method implementations
ls src/flashsvd/finetune/*.py           # Fine-tuning module
ls src/flashsvd/ui/*.py                 # Web UI

# Low-level implementation (research code)
ls src/kernels/*.py                     # Triton kernels
ls src/utils/*.py                       # SVD math and blocks

# Experiment code (reference)
ls experiments/BERT/*.py                # BERT experiments
ls experiments/BERTFW/*.py              # FWSVD experiments
ls decoders/gpt2/*.py                   # GPT-2 experiments
ls decoders/llama/*.py                  # LLaMA experiments

# Testing
ls test/scripts/*.sh                    # Shell test scripts
ls test/scripts/*.py                    # Python test suite

# Documentation
ls *.md                                 # All Markdown documentation

# Configuration
cat pyproject.toml                      # Package configuration
cat requirements.txt                    # Dependency list
```

---

**Last Updated**: 2026-01-30
**Version**: v0.1.0
**Status**: M1-M6 Complete, Production Ready
